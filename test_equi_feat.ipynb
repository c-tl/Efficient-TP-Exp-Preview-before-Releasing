{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Efficiency Comparison Experiment (1): Equivariant Feature Interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tlchen/anaconda3/envs/mace-ef/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from e3nn import o3\n",
    "from e3nn.o3 import TensorProduct, Irreps\n",
    "import time\n",
    "\n",
    "from sh2f import sh2f_channel\n",
    "from f2sh import f2sh_channel\n",
    "from fft import FFT_channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "const_wigner2gaunt = torch.load(\"constants/const_wigner2gaunt.pt\")\n",
    "\n",
    "sh2f_bases_dict = torch.load(\"constants/coefficient_sh2f.pt\")\n",
    "f2sh_bases_dict = torch.load(\"constants/coefficient_f2sh.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def e3nn_implementation(tp, in1, in2):\n",
    "    \n",
    "    torch.cuda.synchronize()\n",
    "    torch.cuda.synchronize()\n",
    "    start_time = time.time()\n",
    "    \n",
    "    res = tp(in1, in2, weight=torch.ones(tp.weight_numel).to(device))\n",
    "\n",
    "    torch.cuda.synchronize()\n",
    "    torch.cuda.synchronize()\n",
    "    end_time = time.time()  \n",
    "    \n",
    "    return res, end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def efficient_implementation(in1, in2, sh2f_bases, f2sh_bases):\n",
    "\n",
    "    torch.cuda.synchronize()\n",
    "    torch.cuda.synchronize()\n",
    "    start_time = time.time()\n",
    "    \n",
    "    in1_fourier, in2_fourier = sh2f_channel(in1, sh2f_bases), sh2f_channel(in2, sh2f_bases)\n",
    "    out_fourier = FFT_channel(in1_fourier, in2_fourier)\n",
    "    res = f2sh_channel(out_fourier, f2sh_bases)\n",
    "    \n",
    "    torch.cuda.synchronize()\n",
    "    torch.cuda.synchronize()\n",
    "    end_time = time.time()  \n",
    "\n",
    "    return res.real, end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GauntFullyConnectedTensorProduct(TensorProduct):\n",
    "\n",
    "    def __init__(\n",
    "        self, irreps_in1, irreps_in2, irreps_out, irrep_normalization: str = None, path_normalization: str = None, **kwargs\n",
    "    ):\n",
    "        irreps_in1 = o3.Irreps(irreps_in1)\n",
    "        irreps_in2 = o3.Irreps(irreps_in2)\n",
    "        irreps_out = o3.Irreps(irreps_out)\n",
    "\n",
    "        instr = [\n",
    "            (i_1, i_2, i_out, \"uuu\", True, const_wigner2gaunt[ir_out.l, ir_1.l, ir_2.l] ** 2)\n",
    "            for i_1, (_, ir_1) in enumerate(irreps_in1)\n",
    "            for i_2, (_, ir_2) in enumerate(irreps_in2)\n",
    "            for i_out, (_, ir_out) in enumerate(irreps_out)\n",
    "            if ir_out in ir_1 * ir_2\n",
    "        ]\n",
    "        super().__init__(\n",
    "            irreps_in1,\n",
    "            irreps_in2,\n",
    "            irreps_out,\n",
    "            instr,\n",
    "            irrep_normalization=irrep_normalization,\n",
    "            path_normalization=path_normalization,\n",
    "            **kwargs,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_irreps(irreps_3D):\n",
    "    L = irreps_3D.shape[1]\n",
    "    irreps_1D = irreps_3D[:, 0, L - 1 : L].flatten()\n",
    "    for l in range(1, L):\n",
    "        irreps_1D = torch.cat((irreps_1D, (irreps_3D[:, l, -l + L - 1 : l + L].flatten())))\n",
    "    return irreps_1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_input(L, num_channel):\n",
    "    '''\n",
    "    Generate random input irreps with degrees of [0, L) and channels of `num_channel`.\n",
    "    '''\n",
    "    in1_sh, in2_sh=torch.rand(num_channel, L, 2 * L - 1).to(device), torch.rand(num_channel, L, 2 * L - 1).to(device)\n",
    "    for l in range(L):\n",
    "        for m in range(-L+1,L):\n",
    "            if m<-l or m>l:\n",
    "                in1_sh[:, l, m + L - 1], in2_sh[:, l, m + L - 1] = 0, 0\n",
    "    in1_e3nn, in2_e3nn = flatten_irreps(in1_sh).to(device), flatten_irreps(in2_sh).to(device)\n",
    "    return in1_e3nn, in2_e3nn, in1_sh, in2_sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_equi_feat(L, channel, n_sample=10, err_tolerance=1e-4):\n",
    "    '''\n",
    "    Compare the time and results for different implementation methods.\n",
    "    The input irreps have degrees of [0, L) and channels of `num_channel`.\n",
    "    The final results is averaged over `n_sample` experiments over random inputs.\n",
    "    The difference of the results from different method is less than `err_tolerance`.\n",
    "    '''\n",
    "\n",
    "    # e3nn needed\n",
    "    irreps_in1 = Irreps([(channel, (l, (-1)**l)) for l in range(L)])\n",
    "    irreps_in2 = Irreps([(channel, (l, (-1)**l)) for l in range(L)])\n",
    "    irreps_out = Irreps([(channel, (l, (-1)**l)) for l in range(2 * L - 1)])\n",
    "    e3nn_tp = GauntFullyConnectedTensorProduct(\n",
    "        irreps_in1, irreps_in2, irreps_out,\n",
    "        irrep_normalization='none', path_normalization='none', \n",
    "        internal_weights = False, shared_weights = True\n",
    "    ).to(device)\n",
    "\n",
    "    # gaunt needed\n",
    "    sh2f_bases, f2sh_bases = sh2f_bases_dict[L], f2sh_bases_dict[2 * L - 1]\n",
    "    sh2f_bases, f2sh_bases = sh2f_bases.to(device), f2sh_bases.to(device)\n",
    "    \n",
    "    # compare different methods\n",
    "    e3nn_times, efficient_times = torch.zeros(n_sample),torch.zeros(n_sample)\n",
    "    for i in range(n_sample):\n",
    "        in1_e3nn, in2_e3nn, in1_sh, in2_sh = random_input(L, channel)\n",
    "\n",
    "        e3nn_res, e3nn_time = e3nn_implementation(e3nn_tp, in1_e3nn, in2_e3nn)\n",
    "        efficient_res, efficient_time = efficient_implementation(in1_sh, in2_sh, sh2f_bases, f2sh_bases)\n",
    "\n",
    "        efficient_res_flatten = flatten_irreps(efficient_res)\n",
    "        # TC: compare the results\n",
    "        assert (abs(e3nn_res - efficient_res_flatten) < err_tolerance).all(), f\"Max Error is {abs(e3nn_res - efficient_res_flatten).max()}!\"\n",
    "        e3nn_times[i], efficient_times[i] = e3nn_time, efficient_time\n",
    "    print(\"Sanity Check Passed!\")\n",
    "    \n",
    "    # @T.C: compare the time\n",
    "    e3nn_mean, e3nn_std = e3nn_times.mean(), e3nn_times.std()\n",
    "    efficient_mean, efficient_std = efficient_times.mean(), efficient_times.std()\n",
    "    print(f\"e3nn takes {e3nn_mean*1000:.2f} ± {e3nn_std*1000:.2f} ms\")\n",
    "    print(f\"Efficient takes {efficient_mean*1000:.2f} ± {efficient_std*1000:.2f} ms\")\n",
    "    print(f\"L = {L}, C = {channel} efficient is {e3nn_mean / efficient_mean:.2f} x faster\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments across Different Degrees (L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Check Passed!\n",
      "e3nn takes 6.67 ± 12.79 ms\n",
      "Efficient takes 0.76 ± 0.58 ms\n",
      "L = 2, C = 128 efficient is 8.78 x faster\n"
     ]
    }
   ],
   "source": [
    "compare_equi_feat(2, channel=128, err_tolerance=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Check Passed!\n",
      "e3nn takes 11.39 ± 20.39 ms\n",
      "Efficient takes 0.82 ± 0.55 ms\n",
      "L = 3, C = 128 efficient is 13.95 x faster\n"
     ]
    }
   ],
   "source": [
    "compare_equi_feat(3, channel=128, err_tolerance=5e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Check Passed!\n",
      "e3nn takes 138.60 ± 412.91 ms\n",
      "Efficient takes 2.31 ± 4.69 ms\n",
      "L = 4, C = 128 efficient is 59.88 x faster\n"
     ]
    }
   ],
   "source": [
    "compare_equi_feat(4, channel=128, err_tolerance=5e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Check Passed!\n",
      "e3nn takes 211.10 ± 629.78 ms\n",
      "Efficient takes 3.06 ± 2.80 ms\n",
      "L = 5, C = 128 efficient is 69.08 x faster\n"
     ]
    }
   ],
   "source": [
    "compare_equi_feat(5, channel=128, err_tolerance=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Check Passed!\n",
      "e3nn takes 326.77 ± 986.02 ms\n",
      "Efficient takes 2.63 ± 4.05 ms\n",
      "L = 6, C = 128 efficient is 124.16 x faster\n"
     ]
    }
   ],
   "source": [
    "compare_equi_feat(6, channel=128, err_tolerance=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Check Passed!\n",
      "e3nn takes 403.43 ± 1186.38 ms\n",
      "Efficient takes 2.28 ± 0.40 ms\n",
      "L = 7, C = 128 efficient is 176.76 x faster\n"
     ]
    }
   ],
   "source": [
    "compare_equi_feat(7, channel=128, err_tolerance=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Check Passed!\n",
      "e3nn takes 678.58 ± 1972.26 ms\n",
      "Efficient takes 3.48 ± 5.15 ms\n",
      "L = 8, C = 128 efficient is 194.92 x faster\n"
     ]
    }
   ],
   "source": [
    "compare_equi_feat(8, channel=128, err_tolerance=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Check Passed!\n",
      "e3nn takes 852.36 ± 2195.77 ms\n",
      "Efficient takes 7.16 ± 16.22 ms\n",
      "L = 9, C = 128 efficient is 118.98 x faster\n"
     ]
    }
   ],
   "source": [
    "compare_equi_feat(9, channel=128, err_tolerance=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Check Passed!\n",
      "e3nn takes 914.15 ± 2529.23 ms\n",
      "Efficient takes 6.14 ± 11.91 ms\n",
      "L = 10, C = 128 efficient is 148.97 x faster\n"
     ]
    }
   ],
   "source": [
    "compare_equi_feat(10, channel=128, err_tolerance=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Check Passed!\n",
      "e3nn takes 1194.65 ± 3215.20 ms\n",
      "Efficient takes 2.34 ± 0.76 ms\n",
      "L = 11, C = 128 efficient is 510.46 x faster\n"
     ]
    }
   ],
   "source": [
    "compare_equi_feat(11, channel=128, err_tolerance=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Check Passed!\n",
      "e3nn takes 1349.64 ± 3699.24 ms\n",
      "Efficient takes 2.81 ± 0.98 ms\n",
      "L = 12, C = 128 efficient is 480.06 x faster\n"
     ]
    }
   ],
   "source": [
    "compare_equi_feat(12, channel=128, err_tolerance=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Check Passed!\n",
      "e3nn takes 1538.02 ± 4043.94 ms\n",
      "Efficient takes 2.92 ± 2.05 ms\n",
      "L = 13, C = 128 efficient is 526.64 x faster\n"
     ]
    }
   ],
   "source": [
    "compare_equi_feat(13, channel=128, err_tolerance=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Check Passed!\n",
      "e3nn takes 2270.26 ± 5585.58 ms\n",
      "Efficient takes 3.07 ± 0.99 ms\n",
      "L = 14, C = 128 efficient is 739.37 x faster\n"
     ]
    }
   ],
   "source": [
    "compare_equi_feat(14, channel=128, err_tolerance=1e-3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fast",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
