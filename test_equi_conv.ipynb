{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Efficiency Comparison Experiment (2): Equivariant Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tlchen/anaconda3/envs/mace-ef/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from e3nn import o3\n",
    "from e3nn.o3 import TensorProduct, Irreps, wigner_3j, spherical_harmonics\n",
    "import time\n",
    "\n",
    "from sh2f import sh2f\n",
    "from f2sh import f2sh\n",
    "from fft import FFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "const_wigner2gaunt = torch.load(\"constants/const_wigner2gaunt.pt\")\n",
    "\n",
    "sh2f_bases_dict = torch.load(\"constants/coefficient_sh2f.pt\")\n",
    "f2sh_bases_dict = torch.load(\"constants/coefficient_f2sh.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def e3nn_implementation(tp, in1, in2):   \n",
    "\n",
    "    torch.cuda.synchronize()\n",
    "    torch.cuda.synchronize()\n",
    "    start_time = time.time()\n",
    "\n",
    "    res = tp(in1, in2, weight=torch.ones(tp.weight_numel).to(device))\n",
    "    \n",
    "    torch.cuda.synchronize()\n",
    "    torch.cuda.synchronize()\n",
    "    end_time = time.time()  \n",
    "    \n",
    "    return res, end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @T.C.: Code from eSCN implementation\n",
    "\n",
    "# Borrowed from e3nn @ 0.4.0:\n",
    "# https://github.com/e3nn/e3nn/blob/0.4.0/e3nn/o3/_wigner.py#L10\n",
    "# _Jd is a list of tensors of shape (2l+1, 2l+1)\n",
    "_Jd = torch.load(\"constants/Jd.pt\")\n",
    "\n",
    "# Borrowed from e3nn @ 0.4.0:\n",
    "# https://github.com/e3nn/e3nn/blob/0.4.0/e3nn/o3/_wigner.py#L37\n",
    "#\n",
    "# In 0.5.0, e3nn shifted to torch.matrix_exp which is significantly slower:\n",
    "# https://github.com/e3nn/e3nn/blob/0.5.0/e3nn/o3/_wigner.py#L92\n",
    "\n",
    "def _z_rot_mat(angle: torch.Tensor, lv: int) -> torch.Tensor:\n",
    "        shape, device, dtype = angle.shape, angle.device, angle.dtype\n",
    "        M = angle.new_zeros((*shape, 2 * lv + 1, 2 * lv + 1))\n",
    "        inds = torch.arange(0, 2 * lv + 1, 1, device=device)\n",
    "        reversed_inds = torch.arange(2 * lv, -1, -1, device=device)\n",
    "        frequencies = torch.arange(lv, -lv - 1, -1, dtype=dtype, device=device)\n",
    "        M[..., inds, reversed_inds] = torch.sin(frequencies * angle[..., None])\n",
    "        M[..., inds, inds] = torch.cos(frequencies * angle[..., None])\n",
    "        return M\n",
    "\n",
    "def wigner_D(lval, alpha, beta, gamma):\n",
    "    if not lval < len(_Jd):\n",
    "        return o3.wigner_D(lval, torch.tensor([alpha]),torch.tensor([beta]), torch.tensor([gamma]))\n",
    "\n",
    "    alpha, beta, gamma = torch.broadcast_tensors(alpha, beta, gamma)\n",
    "    J = _Jd[lval].to(dtype=alpha.dtype, device=device)\n",
    "    Xa = _z_rot_mat(alpha, lval).to(device)\n",
    "    Xb = _z_rot_mat(beta, lval).to(device)\n",
    "    Xc = _z_rot_mat(gamma, lval).to(device)\n",
    "    return Xa @ J @ Xb @ J @ Xc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def escn_implementation(C, in1, L, r):\n",
    "\n",
    "    torch.cuda.synchronize()\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    alpha, beta = o3.xyz_to_angles(r)\n",
    "    alpha, beta = alpha.to(device), beta.to(device)\n",
    "    wigner = torch.zeros(2*L-1, 4*L-3, 4*L-3, device=device)\n",
    "    for l in range(2*L-1):\n",
    "        block = wigner_D(l, torch.tensor([0.]), -beta, -alpha)\n",
    "        start = -l + 2*(L-1)\n",
    "        end = l + 2*L-1\n",
    "        wigner[l, start:end, start:end] = block\n",
    "    start_mid, end_mid = L-1, 3*L-2\n",
    "    in1_rot = torch.bmm(wigner[:L, start_mid:end_mid, start_mid:end_mid], in1.unsqueeze(-1))\n",
    "    res_rot_pos = (C[:, :, :, :, 0:1] * in1_rot.unsqueeze(0).unsqueeze(0)).sum(dim=1).sum(dim=1)\n",
    "    res_rot_neg = (C[:, :, :, :, 1:2] * in1_rot.flip(dims=[1]).unsqueeze(0).unsqueeze(0)).sum(dim=1).sum(dim=1)\n",
    "    res_rot = torch.zeros(2*L-1, 4*L-3, 1, device=device)\n",
    "    res_rot[:, start_mid:end_mid, :] = res_rot_pos + res_rot_neg\n",
    "    wigner_inv = wigner.transpose(1, 2)\n",
    "    res = torch.bmm(wigner_inv, res_rot).squeeze(-1)\n",
    "\n",
    "    torch.cuda.synchronize()\n",
    "    torch.cuda.synchronize()\n",
    "    end_time = time.time()  \n",
    "    \n",
    "    return res, end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def efficient_implementation(in1, in2, sh2f_bases, f2sh_bases):\n",
    "    \n",
    "    torch.cuda.synchronize()\n",
    "    torch.cuda.synchronize()\n",
    "    start_time = time.time()\n",
    "\n",
    "    in1_fourier, in2_fourier = sh2f(in1, sh2f_bases), sh2f(in2, sh2f_bases)\n",
    "    out_fourier = FFT(in1_fourier, in2_fourier)\n",
    "    res = f2sh(out_fourier, f2sh_bases)\n",
    "\n",
    "    torch.cuda.synchronize()\n",
    "    torch.cuda.synchronize()\n",
    "    end_time = time.time()  \n",
    "\n",
    "    return res.real, end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GauntFullyConnectedTensorProduct(TensorProduct):\n",
    "\n",
    "    def __init__(\n",
    "        self, irreps_in1, irreps_in2, irreps_out, irrep_normalization: str = None, path_normalization: str = None, **kwargs\n",
    "    ):\n",
    "        irreps_in1 = Irreps(irreps_in1)\n",
    "        irreps_in2 = Irreps(irreps_in2)\n",
    "        irreps_out = Irreps(irreps_out)\n",
    "\n",
    "        instr = [\n",
    "            (i_1, i_2, i_out, \"uvw\", True, const_wigner2gaunt[ir_out.l, ir_1.l, ir_2.l] ** 2)\n",
    "            for i_1, (_, ir_1) in enumerate(irreps_in1)\n",
    "            for i_2, (_, ir_2) in enumerate(irreps_in2)\n",
    "            for i_out, (_, ir_out) in enumerate(irreps_out)\n",
    "            if ir_out in ir_1 * ir_2\n",
    "        ]\n",
    "        super().__init__(\n",
    "            irreps_in1,\n",
    "            irreps_in2,\n",
    "            irreps_out,\n",
    "            instr,\n",
    "            irrep_normalization=irrep_normalization,\n",
    "            path_normalization=path_normalization,\n",
    "            **kwargs,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_irreps(irreps_2D):\n",
    "    L = irreps_2D.shape[0]\n",
    "    irreps_1D = irreps_2D[0, L - 1 : L]\n",
    "    for l in range(1, L):\n",
    "        irreps_1D = torch.cat((irreps_1D, irreps_2D[l, -l + L - 1 : l + L]))\n",
    "    return irreps_1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_input(L):\n",
    "    sh_coef_in1 =torch.rand(L, 2 * L - 1).to(device)\n",
    "    for l in range(L):\n",
    "        for m in range(-L+1,L):\n",
    "            if m<-l or m>l:\n",
    "                sh_coef_in1[l, m + L - 1] = 0\n",
    "    e3nn_in1 = flatten_irreps(sh_coef_in1).to(device)\n",
    "    return e3nn_in1, sh_coef_in1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_spherical_harmonics_1D(L, r, normalize=True, normalization=\"norm\"):\n",
    "    res = spherical_harmonics(0, r, normalize, normalization)\n",
    "    for l in range(1, L):\n",
    "        res = torch.cat((res, o3.spherical_harmonics(l, r, normalize, normalization)))\n",
    "    return res\n",
    "\n",
    "def full_spherical_harmonics_2D(L, r, normalize=True, normalization=\"norm\"):\n",
    "    res = torch.zeros(L, 2*L-1)\n",
    "    for l in range(L):\n",
    "        res[l, -l+L-1:l+L] = spherical_harmonics(l, r, normalize, normalization)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_equi_conv(L, n_sample=10, err_tolerance=1e-4):\n",
    "    '''\n",
    "    Compare the time and results for different implementation methods.\n",
    "    The input irreps have degrees of [0, L).\n",
    "    The final results is averaged over `n_sample` experiments over random inputs.\n",
    "    The difference of the results from different method is less than `err_tolerance`.\n",
    "    '''\n",
    "\n",
    "    # e3nn needed\n",
    "    irreps_in1 = Irreps([(1, (l, (-1)**l)) for l in range(L)])\n",
    "    irreps_in2 = Irreps([(1, (l, (-1)**l)) for l in range(L)])\n",
    "    irreps_out = Irreps([(1, (l, (-1)**l)) for l in range(2 * L - 1)])\n",
    "    tp = GauntFullyConnectedTensorProduct(\n",
    "        irreps_in1, irreps_in2, irreps_out,\n",
    "        irrep_normalization='none', path_normalization='none', \n",
    "        internal_weights = False, shared_weights = True\n",
    "    ).to(device)\n",
    "\n",
    "    # eSCN needed\n",
    "    C = torch.zeros(2*L-1, L, L, 2*L-1, 2, device=device)\n",
    "    for lo in range(2*L-1):\n",
    "        for lf in range(L):\n",
    "            for li in range(L):\n",
    "                if abs(lf - li) <= lo <= lf + li:\n",
    "                    w3j = wigner_3j(lo, lf, li)\n",
    "                    if (lo + li + lf) % 2 == 0:\n",
    "                        m = min(li, lo)\n",
    "                        for mo in range(-m, m+1):\n",
    "                            C[lo, lf, li, mo+L-1, 0] = w3j[mo+lo, lf, mo+li]\n",
    "                            C[lo, lf, li, mo+L-1, 1] = 0 if mo==0 else w3j[mo+lo, lf, -mo+li]\n",
    "                        C[lo, lf, li] *= const_wigner2gaunt[lo, lf, li]  \n",
    "\n",
    "    # gaunt needed\n",
    "    sh2f_bases, f2sh_bases = sh2f_bases_dict[L], f2sh_bases_dict[2 * L - 1]\n",
    "    sh2f_bases, f2sh_bases = sh2f_bases.to(device), f2sh_bases.to(device)\n",
    "    \n",
    "    # compare different methods\n",
    "    e3nn_times, escn_times, efficient_times = torch.zeros(n_sample), torch.zeros(n_sample), torch.zeros(n_sample)\n",
    "    for i in range(n_sample):\n",
    "        e3nn_in1, sh_coef_in1 = random_input(L)\n",
    "        r = torch.rand(3).to(device)\n",
    "        r /= r.norm()\n",
    "        \n",
    "        e3nn_in2 = full_spherical_harmonics_1D(L, r, normalize=True, normalization=\"norm\").to(device)\n",
    "        efficient_in2 = full_spherical_harmonics_2D(L, r, normalize=True, normalization=\"norm\").to(device)\n",
    "        \n",
    "        e3nn_res, e3nn_time = e3nn_implementation(tp, e3nn_in1, e3nn_in2)\n",
    "        escn_res, escn_time = escn_implementation(C, sh_coef_in1, L, r)\n",
    "        efficient_res, efficient_time = efficient_implementation(sh_coef_in1, efficient_in2, sh2f_bases, f2sh_bases)\n",
    "\n",
    "        # TC: compare the results\n",
    "        escn_flatten = flatten_irreps(escn_res)\n",
    "        efficient_res_flatten = flatten_irreps(efficient_res)\n",
    "        assert (abs(e3nn_res - escn_flatten) < err_tolerance).all(), f\"Max Error is {abs(e3nn_res - escn_flatten).max()}\"\n",
    "        assert (abs(e3nn_res - efficient_res_flatten) < err_tolerance).all(), f\"Max Error is {abs(e3nn_res - efficient_res_flatten).max()}\"\n",
    "        e3nn_times[i], escn_times[i], efficient_times[i] = e3nn_time, escn_time, efficient_time\n",
    "    print(\"Sanity Check Passed!\")\n",
    "    \n",
    "    # @T.C: compare the time\n",
    "    e3nn_mean, e3nn_std = e3nn_times.mean(), e3nn_times.std()\n",
    "    escn_mean, escn_std = escn_times.mean(), escn_times.std()\n",
    "    efficient_mean, efficient_std = efficient_times.mean(), efficient_times.std()\n",
    "    print(f\"e3nn takes {e3nn_mean*1000:.2f} ± {e3nn_std*1000:.2f} ms\")\n",
    "    print(f\"escn takes {escn_mean*1000:.2f} ± {escn_std*1000:.2f} ms\")\n",
    "    print(f\"Efficient takes {efficient_mean*1000:.2f} ± {efficient_std*1000:.2f} ms\")\n",
    "    print(f\"L = {L} efficient is {e3nn_mean / efficient_mean:.2f} x faster than e3nn\")\n",
    "    print(f\"L = {L} efficient is {escn_mean / efficient_mean:.2f} x faster than escn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments across Different Degrees (L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Check Passed!\n",
      "e3nn takes 3.91 ± 4.44 ms\n",
      "escn takes 5.14 ± 4.22 ms\n",
      "Efficient takes 0.84 ± 0.52 ms\n",
      "L = 2 efficient is 4.64 x faster than e3nn\n",
      "L = 2 efficient is 6.09 x faster than escn\n"
     ]
    }
   ],
   "source": [
    "compare_equi_conv(L=2, err_tolerance=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Check Passed!\n",
      "e3nn takes 144.36 ± 437.13 ms\n",
      "escn takes 6.02 ± 1.56 ms\n",
      "Efficient takes 0.88 ± 0.53 ms\n",
      "L = 3 efficient is 163.23 x faster than e3nn\n",
      "L = 3 efficient is 6.80 x faster than escn\n"
     ]
    }
   ],
   "source": [
    "compare_equi_conv(L=3, err_tolerance=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Check Passed!\n",
      "e3nn takes 218.48 ± 661.67 ms\n",
      "escn takes 13.24 ± 10.51 ms\n",
      "Efficient takes 2.71 ± 5.62 ms\n",
      "L = 4 efficient is 80.59 x faster than e3nn\n",
      "L = 4 efficient is 4.89 x faster than escn\n"
     ]
    }
   ],
   "source": [
    "compare_equi_conv(L=4, err_tolerance=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Check Passed!\n",
      "e3nn takes 368.57 ± 1069.33 ms\n",
      "escn takes 14.11 ± 11.90 ms\n",
      "Efficient takes 2.85 ± 6.09 ms\n",
      "L = 5 efficient is 129.45 x faster than e3nn\n",
      "L = 5 efficient is 4.96 x faster than escn\n"
     ]
    }
   ],
   "source": [
    "compare_equi_conv(L=5, err_tolerance=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Check Passed!\n",
      "e3nn takes 343.13 ± 932.05 ms\n",
      "escn takes 16.52 ± 14.28 ms\n",
      "Efficient takes 2.33 ± 5.40 ms\n",
      "L = 6 efficient is 147.33 x faster than e3nn\n",
      "L = 6 efficient is 7.09 x faster than escn\n"
     ]
    }
   ],
   "source": [
    "compare_equi_conv(L=6, err_tolerance=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Check Passed!\n",
      "e3nn takes 482.23 ± 1321.75 ms\n",
      "escn takes 28.85 ± 23.35 ms\n",
      "Efficient takes 1.59 ± 0.91 ms\n",
      "L = 7 efficient is 304.04 x faster than e3nn\n",
      "L = 7 efficient is 18.19 x faster than escn\n"
     ]
    }
   ],
   "source": [
    "compare_equi_conv(L=7, err_tolerance=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Check Passed!\n",
      "e3nn takes 510.16 ± 1297.93 ms\n",
      "escn takes 34.98 ± 23.27 ms\n",
      "Efficient takes 1.98 ± 3.23 ms\n",
      "L = 8 efficient is 257.97 x faster than e3nn\n",
      "L = 8 efficient is 17.69 x faster than escn\n"
     ]
    }
   ],
   "source": [
    "compare_equi_conv(L=8, err_tolerance=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Check Passed!\n",
      "e3nn takes 622.42 ± 1689.18 ms\n",
      "escn takes 59.15 ± 20.66 ms\n",
      "Efficient takes 1.80 ± 0.98 ms\n",
      "L = 9 efficient is 346.68 x faster than e3nn\n",
      "L = 9 efficient is 32.95 x faster than escn\n"
     ]
    }
   ],
   "source": [
    "compare_equi_conv(L=9, err_tolerance=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Check Passed!\n",
      "e3nn takes 1223.46 ± 3232.62 ms\n",
      "escn takes 136.20 ± 120.18 ms\n",
      "Efficient takes 4.94 ± 7.88 ms\n",
      "L = 10 efficient is 247.91 x faster than e3nn\n",
      "L = 10 efficient is 27.60 x faster than escn\n"
     ]
    }
   ],
   "source": [
    "compare_equi_conv(L=10, err_tolerance=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Check Passed!\n",
      "e3nn takes 2077.59 ± 5458.77 ms\n",
      "escn takes 245.45 ± 172.58 ms\n",
      "Efficient takes 3.66 ± 3.31 ms\n",
      "L = 11 efficient is 567.63 x faster than e3nn\n",
      "L = 11 efficient is 67.06 x faster than escn\n"
     ]
    }
   ],
   "source": [
    "compare_equi_conv(L=11, err_tolerance=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Check Passed!\n",
      "e3nn takes 2560.89 ± 6695.64 ms\n",
      "escn takes 308.97 ± 215.83 ms\n",
      "Efficient takes 2.47 ± 1.06 ms\n",
      "L = 12 efficient is 1035.64 x faster than e3nn\n",
      "L = 12 efficient is 124.95 x faster than escn\n"
     ]
    }
   ],
   "source": [
    "compare_equi_conv(L=12, err_tolerance=5e-4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fast",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
